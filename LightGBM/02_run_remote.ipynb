{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "# Configure experiment\n",
        "ws = Workspace.from_config()\n",
        "exp = Experiment(workspace=ws, name=\"titanic-lgbm-remote\")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1606669780803
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "def get_aml_cluster(ws, cluster_name, vm_size='STANDARD_D12_V2', max_nodes=4):\n",
        "    try:\n",
        "        cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    except ComputeTargetException:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size, max_nodes=max_nodes)\n",
        "        cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "    cluster.wait_for_completion(show_output=True)    \n",
        "    return cluster"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1606669837014
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aml_cluster = get_aml_cluster(ws, cluster_name=\"d12compute\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1606669841518
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.read_csv('../train.csv')\n",
        "df.drop(['PassengerId'], axis=1, inplace=True)\n",
        "\n",
        "# 'Embarked' is stored as letters, so fit a label encoder to the train set to use in the loop\n",
        "embarked_encoder = LabelEncoder()\n",
        "embarked_encoder.fit(df['Embarked'].fillna('Null'))\n",
        " \n",
        "# Record anyone travelling alone\n",
        "df['Alone'] = (df['SibSp'] == 0) & (df['Parch'] == 0)\n",
        "\n",
        "# Transform 'Embarked'\n",
        "df['Embarked'].fillna('Null', inplace=True)\n",
        "df['Embarked'] = embarked_encoder.transform(df['Embarked'])\n",
        "\n",
        "# Transform 'Sex'\n",
        "df.loc[df['Sex'] == 'female','Sex'] = 0\n",
        "df.loc[df['Sex'] == 'male','Sex'] = 1\n",
        "df['Sex'] = df['Sex'].astype('int8')\n",
        "\n",
        "# Drop features that seem unusable. Save passenger ids if test\n",
        "df.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1606669870248
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azureml.core import Dataset\n",
        "\n",
        "def df_to_dataset(ws, df, name, data_dir='./data'):\n",
        "    data_path = os.path.join(data_dir, \"%s.csv\" % name)\n",
        "    \n",
        "    # save data to disk\n",
        "    df.to_csv(data_path)\n",
        "    \n",
        "    # get the default datastore\n",
        "    datastore = ws.get_default_datastore()\n",
        "\n",
        "    # upload the data to the datastore\n",
        "    datastore.upload(src_dir=data_dir, target_path=data_dir)\n",
        "    \n",
        "    # create a dataset\n",
        "    dataset = Dataset.Tabular.from_delimited_files(datastore.path(data_path))\n",
        "    \n",
        "    # register the dataset\n",
        "    dataset.register(workspace=ws, name=name, create_new_version=True)\n",
        "    return dataset"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1606669945772
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_to_dataset(ws, df, 'titanic_cleaned')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 1 files\n",
            "Uploading ./data/titanic_cleaned.csv\n",
            "Uploaded ./data/titanic_cleaned.csv, 1 files out of an estimated total of 1\n",
            "Uploaded 1 files\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "{\n  \"source\": [\n    \"('workspaceblobstore', './data/titanic_cleaned.csv')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\",\n    \"ParseDelimited\",\n    \"DropColumns\",\n    \"SetColumnTypes\"\n  ]\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1606670008678
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
        " \n",
        "def run_config(target, packages=None):\n",
        "    packages = packages or []\n",
        "    config = RunConfiguration()\n",
        "\n",
        "    config.target = target\n",
        "    config.environment.docker.enabled = True\n",
        "    config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
        "    \n",
        "    azureml_pip_packages = [\n",
        "        'azureml-defaults', 'azureml-contrib-interpret', 'azureml-core', 'azureml-telemetry',\n",
        "        'azureml-interpret', 'sklearn-pandas', 'azureml-dataprep'\n",
        "    ]\n",
        "    \n",
        "    config.environment.python.user_managed_dependencies = False\n",
        "    config.environment.python.conda_dependencies = CondaDependencies.create(pip_packages=azureml_pip_packages + packages)\n",
        "    \n",
        "    return config"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1606670099574
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a remote run configuration\n",
        "run_amlcompute = run_config(aml_cluster, [\n",
        "    'numpy', 'pandas', 'matplotlib', 'seaborn', 'scikit-learn', 'lightgbm', 'umap-learn'\n",
        "])"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1606670102606
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_params = [\n",
        "    '--boosting', 'dart',\n",
        "    '--learning-rate', '0.05',\n",
        "    '--drop-rate', '0.15',\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1606670107216
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "script = 'train_lightgbm.py'\n",
        "script_folder = os.getcwd()\n",
        "\n",
        "src = ScriptRunConfig(\n",
        "  source_directory=script_folder,\n",
        "  script=script,\n",
        "  run_config=run_amlcompute,\n",
        "  arguments=script_params)\n",
        "\n",
        "run = exp.submit(src)\n",
        "\n",
        "RunDetails(run).show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed9ee8e5e02942c6b8ca658be3f8686b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Queued\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/titanic-lgbm-remote/runs/titanic-lgbm-remote_1606671643_495b994c?wsid=/subscriptions/da21a094-26a3-472f-991b-e2b11979af40/resourcegroups/agoge/workspaces/agogemls\", \"run_id\": \"titanic-lgbm-remote_1606671643_495b994c\", \"run_properties\": {\"run_id\": \"titanic-lgbm-remote_1606671643_495b994c\", \"created_utc\": \"2020-11-29T17:40:52.538376Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"7bdef684-6b4a-47ef-80da-9ddfdf8f9d49\", \"azureml.git.repository_uri\": \"https://github.com/szelor/Titanic\", \"mlflow.source.git.repoURL\": \"https://github.com/szelor/Titanic\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Queued\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:00:41\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"Your job is submitted in Azure cloud and we are monitoring to get logs...\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.16.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1606671660070
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run.get_portal_url())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://ml.azure.com/experiments/titanic-lgbm-remote/runs/titanic-lgbm-remote_1606670115_b6048791?wsid=/subscriptions/da21a094-26a3-472f-991b-e2b11979af40/resourcegroups/agoge/workspaces/agogemls\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1606670671684
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}